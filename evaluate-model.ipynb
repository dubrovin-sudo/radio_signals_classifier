{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/aleksandrdubrovin/evaluate-model?scriptVersionId=88379943\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"## Description\nI was working with one third part of dataset (851968 signals), I found myself running into problems with memory shortages on Kaggle’s default and decided to use powerful Google Cloud Platform virtual machine instance.\nI used the virtual machine instance n1-standard-8 (8 vCPU, 30 GB memory) with a NVIDIA Tesla V100 GPU to run my training session.\nThis required about 7.5 hours of training time","metadata":{}},{"cell_type":"markdown","source":"## Import","metadata":{}},{"cell_type":"code","source":"import os\nimport keras\nimport numpy as np \nimport pandas as pd \nimport itertools\nfrom sklearn.model_selection import train_test_split\nfrom keras.models import Model, load_model\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\n%matplotlib inline","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:01:37.968629Z","iopub.execute_input":"2022-02-16T15:01:37.969017Z","iopub.status.idle":"2022-02-16T15:01:45.33931Z","shell.execute_reply.started":"2022-02-16T15:01:37.968922Z","shell.execute_reply":"2022-02-16T15:01:45.338408Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Constants","metadata":{}},{"cell_type":"code","source":"for dirname, _, filenames in os.walk('/kaggle/input'):    \n    files = {}\n    for filename in filenames:        \n        files[filename] = os.path.join(dirname, filename)\nprint(files)\n\n# Open classes.txt\nwith open(files['classes.txt']) as file: \n\n   classes = file.read()\n\ndef str_to_list(line):\n    line = line.replace('\\n','')\n    line = line.replace('classes = ','')\n    line = eval(line)\n    return line\n    \nclasses = str_to_list(classes)\nprint(classes)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-16T15:01:45.340774Z","iopub.execute_input":"2022-02-16T15:01:45.341193Z","iopub.status.idle":"2022-02-16T15:01:45.36017Z","shell.execute_reply.started":"2022-02-16T15:01:45.341158Z","shell.execute_reply":"2022-02-16T15:01:45.359563Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Load data","metadata":{}},{"cell_type":"code","source":"# Upload signals, labels, snrs\nlabels = np.load('/kaggle/input/deepsigio-radioml-201801a-new/labels.npy', mmap_mode = 'r')\nsignals = np.load('/kaggle/input/deepsigio-radioml-201801a-new/signals.npy', mmap_mode = 'r')\nsnrs = np.load('/kaggle/input/deepsigio-radioml-201801a-new/snrs.npy', mmap_mode = 'r')\n\ntrain_acc = np.load('/kaggle/input/deepsigio-radioml-201801a-new/train_acc.npy', mmap_mode = 'r')\nval_acc = np.load('/kaggle/input/deepsigio-radioml-201801a-new/val_acc.npy', mmap_mode = 'r')\ntrain_loss = np.load('/kaggle/input/deepsigio-radioml-201801a-new/train_loss.npy', mmap_mode = 'r')\nval_loss = np.load('/kaggle/input/deepsigio-radioml-201801a-new/val_loss.npy', mmap_mode = 'r')\n\n# Upload model\nmodel_full = load_model(files['model_full_SNR.h5'])","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:01:45.361799Z","iopub.execute_input":"2022-02-16T15:01:45.36254Z","iopub.status.idle":"2022-02-16T15:01:46.534743Z","shell.execute_reply.started":"2022-02-16T15:01:45.362492Z","shell.execute_reply":"2022-02-16T15:01:46.533733Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split arrays for 3 parts (we take only third part of dataset of labeled signals because of the memory)\npart = 3\nsignals = signals[::part, :, :]\nlabels = labels[::part, :]\nsnrs = snrs[::part, :]\n\nprint(signals.shape)\nprint(labels.shape)\nprint(snrs.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:01:46.538106Z","iopub.execute_input":"2022-02-16T15:01:46.538366Z","iopub.status.idle":"2022-02-16T15:01:46.546103Z","shell.execute_reply.started":"2022-02-16T15:01:46.538336Z","shell.execute_reply":"2022-02-16T15:01:46.544995Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ndarray to array\nsnrs = np.ravel(snrs)\nprint(f\"All possible SNRS: {np.unique(snrs)} db\")","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:01:46.547697Z","iopub.execute_input":"2022-02-16T15:01:46.548196Z","iopub.status.idle":"2022-02-16T15:01:46.961572Z","shell.execute_reply.started":"2022-02-16T15:01:46.548152Z","shell.execute_reply":"2022-02-16T15:01:46.960696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Masked numpy array \nc = np.ma.masked_where(snrs > 8, snrs)\nmsk = c.mask\n# Count unique elements in array\nprint(np.unique(c.mask, return_counts=True))","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:01:46.962857Z","iopub.execute_input":"2022-02-16T15:01:46.963108Z","iopub.status.idle":"2022-02-16T15:01:46.990244Z","shell.execute_reply.started":"2022-02-16T15:01:46.963078Z","shell.execute_reply":"2022-02-16T15:01:46.989317Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Mask array of signals and labels (snrs > 8)\nsignals = signals[msk]\nlabels = labels[msk]\n\nprint(len(signals))","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:01:46.991605Z","iopub.execute_input":"2022-02-16T15:01:46.991886Z","iopub.status.idle":"2022-02-16T15:04:51.474033Z","shell.execute_reply.started":"2022-02-16T15:01:46.991841Z","shell.execute_reply":"2022-02-16T15:04:51.472429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Train|test = 80|20\n\nx_train,x_test, y_train, y_test = train_test_split(signals, labels, train_size=0.8, stratify=labels, random_state = 42)\n\n# print(f\"Количество строк в y_train по классам: {np.bincount(y_train)}\")\n# print(f\"Количество строк в y_test по классам: {np.bincount(y_test)}\")\nprint(x_test.shape)\nprint(y_test.shape)\n\n# Train|validation|test = 64|16|20\nx_train, x_val, y_train, y_val = train_test_split(x_train, y_train, train_size=0.8, stratify=y_train, random_state = 42)\n\n# print(f\"Количество строк в y_train по классам: {np.bincount(y_test)}\")\n# print(f\"Количество строк в y_test по классам: {np.bincount(y_val)}\")\nprint(x_train.shape)\nprint(y_train.shape)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:04:51.476531Z","iopub.execute_input":"2022-02-16T15:04:51.477404Z","iopub.status.idle":"2022-02-16T15:05:15.931407Z","shell.execute_reply.started":"2022-02-16T15:04:51.477357Z","shell.execute_reply":"2022-02-16T15:05:15.930756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluate Model on Test Data","metadata":{}},{"cell_type":"code","source":"# evaluate model on test data\nloss, acc = model_full.evaluate(x_test, y_test, batch_size=32)\nprint('EVALUATING MODEL ON TEST DATA:')\nprint('Test Accuracy: ', str(round(acc*100, 2)), '%')\nprint('\\n')","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:05:15.934876Z","iopub.execute_input":"2022-02-16T15:05:15.936519Z","iopub.status.idle":"2022-02-16T15:06:42.25542Z","shell.execute_reply.started":"2022-02-16T15:05:15.93648Z","shell.execute_reply":"2022-02-16T15:06:42.253419Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The model achieved maximum accuracy of 95.72% on the clean signal dataset (SNR > 8dB).\n\n*Note that the maximum classification accuracy of 62% if you want to test the model to its absolute limits on a mix of clean signals and signals with very high interference. Some of the signals have so much noise that they are virtually unrecognizable.*","metadata":{}},{"cell_type":"markdown","source":"## Confusion Matrix","metadata":{}},{"cell_type":"code","source":"predictions=model_full.predict(x_test)\nclasses_y=np.argmax(predictions,axis=1)\nconf_matrix = confusion_matrix(y_true=np.argmax(y_test,axis=1), y_pred=classes_y)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:06:42.257792Z","iopub.execute_input":"2022-02-16T15:06:42.258191Z","iopub.status.idle":"2022-02-16T15:08:04.041976Z","shell.execute_reply.started":"2022-02-16T15:06:42.258154Z","shell.execute_reply":"2022-02-16T15:08:04.041106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nr_rows = conf_matrix.shape[0]\nnr_cols = conf_matrix.shape[1]\n\nplt.figure(figsize=(18,18), dpi= 200) \nim = plt.imshow(conf_matrix, cmap=plt.cm.Greens)\nax = plt.gca()\nplt.title('Confusion Matrix', fontsize=16) \nplt.ylabel('Actual Labels', fontsize=12)\nplt.xlabel('Predicted Labels', fontsize=12)\ntick_marks = np.arange(len(classes))\nplt.yticks(tick_marks, classes)\n# plt.xticks(tick_marks, classes)\n\nfor i, j in itertools.product(range(nr_rows), range(nr_cols)):\n    plt.text(j, i, conf_matrix[i, j], horizontalalignment='center',\n            color='white' if conf_matrix[i, j] > conf_matrix.max()/2 else 'black')\n    \n\n# Divide existing axes and create new axes\n# at bottom side of image\ndivider = make_axes_locatable(ax)\ncax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\nplt.colorbar(im, cax=cax) ","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:08:04.043038Z","iopub.execute_input":"2022-02-16T15:08:04.0438Z","iopub.status.idle":"2022-02-16T15:08:08.44089Z","shell.execute_reply.started":"2022-02-16T15:08:04.043762Z","shell.execute_reply":"2022-02-16T15:08:08.440162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Conclusions\nReaching maximum accuracy of 62% on a mix of clean signals and signals with very high interference and 95.72% on the clean signal dataset, the model isn't perfect.","metadata":{}},{"cell_type":"code","source":"history = [[train_acc, val_acc],[train_loss, val_loss]]\ntitle = ['Model accuracy', 'Model loss']\nylabel = ['accuracy', 'loss']\nfig = plt.figure(figsize=(20, 7), dpi=80)\nfor i, id in enumerate(title):\n    plt.subplot(1, 2, i+1)\n   \n    plt.plot(history[i][0], label = 'train')\n    plt.plot(history[i][1], label = 'val')\n    plt.title(id)\n    plt.xlabel('epoch')\n    plt.ylabel(ylabel[i])\n    plt.legend(loc='upper right')\nplt.tight_layout(pad=1.7)\n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:08:08.441978Z","iopub.execute_input":"2022-02-16T15:08:08.442294Z","iopub.status.idle":"2022-02-16T15:08:08.855699Z","shell.execute_reply.started":"2022-02-16T15:08:08.442266Z","shell.execute_reply":"2022-02-16T15:08:08.854672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Below is an example of a signal that was mis-classified by the model (AM-SSB-WC signal was mis-classified as a 64QAM signal)","metadata":{}},{"cell_type":"code","source":"idx = [17,18]\nfig = plt.figure(figsize=(20, 5), dpi=80)\nfor i, id in enumerate(idx):\n    plt.subplot(1, 2, i+1)\n    plt.plot(signals[id][:, 0], color='green', label='I component')\n    plt.plot(signals[id][:, 1], color='salmon', label='Q component')\n    plt.title(classes[id])\n    plt.xlabel('Points')\n    plt.ylabel('Amplitude')\n    plt.legend(loc='upper right')\nplt.tight_layout(pad=1.7)","metadata":{"execution":{"iopub.status.busy":"2022-02-16T15:08:08.857111Z","iopub.execute_input":"2022-02-16T15:08:08.857336Z","iopub.status.idle":"2022-02-16T15:08:09.312217Z","shell.execute_reply.started":"2022-02-16T15:08:08.857309Z","shell.execute_reply":"2022-02-16T15:08:09.311345Z"},"trusted":true},"execution_count":null,"outputs":[]}]}